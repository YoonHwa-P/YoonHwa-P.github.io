<!doctype html>
<html lang="ko"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>태그: TextMining - Life in the Mars</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="salmon"><meta name="application-name" content="YoonHwa"><meta name="msapplication-TileImage" content="/img/main.jpg"><meta name="msapplication-TileColor" content="salmon"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="YoonHwa"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="나는 화성인이다."><meta property="og:type" content="blog"><meta property="og:title" content="Life in the Mars"><meta property="og:url" content="https://yoonhwa-p.github.io/"><meta property="og:site_name" content="Life in the Mars"><meta property="og:description" content="나는 화성인이다."><meta property="og:locale" content="ko_KR"><meta property="og:image" content="https://yoonhwa-p.github.io/img/og_image.png"><meta property="article:author" content="YoonHwa"><meta property="article:tag" content="programming, bio"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://YoonHwa-P.github.io"},"headline":"Life in the Mars","image":["https://yoonhwa-p.github.io/img/og_image.png"],"author":{"@type":"Person","name":"YoonHwa"},"publisher":{"@type":"Organization","name":"Life in the Mars","logo":{"@type":"ImageObject","url":"https://yoonhwa-p.github.io/imeges/main.jpg"}},"description":"나는 화성인이다."}</script><link rel="icon" href="/../imeges/main.jpg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://cdn.rawgit.com/innks/NanumSquareRound/master/nanumsquareround.css"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-71105E54VD" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-71105E54VD');</script><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><script data-ad-client="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9661048314566450" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" async></script><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/../imeges/main.jpg" alt="Life in the Mars" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="검색" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">태그</a></li><li class="is-active"><a href="#" aria-current="page">TextMining</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2021-12-17T08:11:16.000Z" title="2021. 12. 17. 오후 5:11:16">2021-12-17</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2021-12-19T04:51:41.664Z" title="2021. 12. 19. 오후 1:51:41">2021-12-19</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/R/">R</a><span> / </span><a class="link-muted" href="/categories/R/data-science/">data_science</a></span><span class="level-item">6분안에 읽기 (약 837 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/12/17/R/classfication_R/">Text Mining in Python</a></h1><div class="content"><hr>
<h3 id="data-불러오기"><a href="#data-불러오기" class="headerlink" title="data 불러오기"></a>data 불러오기</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ---- 데이터 불러오기 ----</span></span><br><span class="line"></span><br><span class="line">library(ggplot2) <span class="comment"># 시각화 코드</span></span><br><span class="line"><span class="comment"># install.packages(&quot;dplyr&quot;)</span></span><br><span class="line"><span class="comment"># install.packages(&quot;tidyr&quot;)</span></span><br><span class="line">library(dplyr) <span class="comment"># 데이터 가공</span></span><br><span class="line">library(reshape) <span class="comment"># 데이터 가공 &lt;-- tidyr</span></span><br><span class="line">library(readr) <span class="comment"># 파일 입출력</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">raw_reviews = read_csv(<span class="string">&quot;data/Womens Clothing E-Commerce Reviews.csv&quot;</span>) %&gt;% select(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># raw_reviews &lt;- raw_reviews %&gt;% select(-1)</span></span><br><span class="line">glimpse(raw_reviews)</span><br><span class="line"></span><br><span class="line">colnames(raw_reviews) &lt;- <span class="built_in">c</span>(<span class="string">&quot;ID&quot;</span>, <span class="string">&quot;Age&quot;</span>, <span class="string">&quot;Title&quot;</span>, <span class="string">&quot;Review&quot;</span>, <span class="string">&quot;Rating&quot;</span>, <span class="string">&quot;Recommend&quot;</span>, <span class="string">&quot;Liked&quot;</span>, <span class="string">&quot;Division&quot;</span>, <span class="string">&quot;Dept&quot;</span>, <span class="string">&quot;Class&quot;</span>)</span><br><span class="line"></span><br><span class="line">glimpse(raw_reviews) </span><br><span class="line"></span><br><span class="line"><span class="comment"># age 리뷰 작성한 고객의 연령</span></span><br><span class="line"><span class="comment"># Title, Review Text 리뷰 제목, 내용</span></span><br><span class="line"><span class="comment"># Rating: 고객이 부여한 평점</span></span><br><span class="line"><span class="comment"># Recommend IND: 추천 여부</span></span><br><span class="line"><span class="comment"># Positive Feedback Count: 좋아요 수치</span></span><br><span class="line"><span class="comment"># Division, Dept, Class --&gt; 상품의 대분류 정보</span></span><br></pre></td></tr></table></figure>

<h3 id="data-전처리"><a href="#data-전처리" class="headerlink" title="data 전처리"></a>data 전처리</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ---- 데이터 전처리 ----</span></span><br><span class="line"><span class="comment"># 결측치 확인</span></span><br><span class="line">colSums(<span class="built_in">is.na</span>(raw_reviews))</span><br><span class="line"></span><br><span class="line">table(raw_reviews$Age)</span><br><span class="line"></span><br><span class="line">age_group = cut(<span class="built_in">as.numeric</span>(raw_reviews$Age), </span><br><span class="line">                breaks = seq(<span class="number">10</span>, <span class="number">100</span>, by = <span class="number">10</span>), </span><br><span class="line">                include.lowest = <span class="literal">TRUE</span>, </span><br><span class="line">                right = <span class="literal">FALSE</span>, </span><br><span class="line">                labels = paste0(seq(<span class="number">10</span>, <span class="number">90</span>, by = <span class="number">10</span>), <span class="string">&quot;th&quot;</span>))</span><br><span class="line"></span><br><span class="line">age_group[<span class="number">1</span>:<span class="number">10</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 새로운 변수 추가</span></span><br><span class="line">raw_reviews$age_group = age_group</span><br><span class="line">table(raw_reviews$age_group)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 감성 사전 데이터셋 변환</span></span><br><span class="line">summary(raw_reviews$Liked)</span><br><span class="line">table(raw_reviews$Liked)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 층화추출? / 임의추출</span></span><br><span class="line">idx = sample(<span class="number">1</span>:nrow(raw_reviews), nrow(raw_reviews) * <span class="number">0.1</span>, replace = <span class="literal">FALSE</span>)</span><br><span class="line"></span><br><span class="line">raw_reviews2 = raw_reviews[idx, ] </span><br><span class="line"></span><br><span class="line">raw_reviews2 %&gt;% </span><br><span class="line">  mutate(pos_binary = ifelse(Liked &gt; <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>)) %&gt;% <span class="comment"># 이산형 변수로 변환</span></span><br><span class="line">  select(Liked, pos_binary) -&gt; pos_binary_df</span><br><span class="line"></span><br><span class="line">pos_binary_df$pos_binary &lt;- as.factor(pos_binary_df$pos_binary)</span><br><span class="line"></span><br><span class="line">table(pos_binary_df$pos_binary) <span class="comment"># 0 부정, 1 긍정</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 키워드 데이터셋 생성</span></span><br><span class="line">REVIEW_TEXT = <span class="built_in">as.character</span>(raw_reviews2$Review)</span><br><span class="line">REVIEW_TEXT = tolower(raw_reviews2$Review)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 단어를 이어 붙인 후, 토큰화된 단어들로 문장 재구성</span></span><br><span class="line">library(tokenizers)</span><br><span class="line"></span><br><span class="line">TEXT_Token = <span class="built_in">c</span>()</span><br><span class="line"><span class="keyword">for</span>(i <span class="keyword">in</span> <span class="number">1</span>:<span class="built_in">length</span>(REVIEW_TEXT)) &#123;</span><br><span class="line">  token_words = unlist(tokenize_word_stems(REVIEW_TEXT[i]))</span><br><span class="line">  Sentence = <span class="string">&quot;&quot;</span></span><br><span class="line">  </span><br><span class="line">  <span class="keyword">for</span> (tw <span class="keyword">in</span> token_words) &#123;</span><br><span class="line">    Sentence = paste(Sentence, tw)</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  TEXT_Token[i] = Sentence</span><br><span class="line">  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Text-전처리"><a href="#Text-전처리" class="headerlink" title="Text 전처리"></a>Text 전처리</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ---- 텍스트 전처리</span></span><br><span class="line">library(tm)</span><br><span class="line"></span><br><span class="line">Corpus_token = Corpus(VectorSource(TEXT_Token))</span><br><span class="line">Corpus_tm_token = tm_map(Corpus_token, removePunctuation)</span><br><span class="line">Corpus_tm_token = tm_map(Corpus_token, removeNumbers)</span><br><span class="line">Corpus_tm_token = tm_map(Corpus_token, removeWords, <span class="built_in">c</span>(stopwords(<span class="string">&quot;English&quot;</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#TDM과 DTM 의 차이 (TDM :term Document Matrix)</span></span><br><span class="line"><span class="comment"># T=ODF . DTM = CountVectprozor(in Python)</span></span><br><span class="line">DTM_Token = DocumentTermMatrix(Corpus_tm_token)</span><br><span class="line">DTM_Matrix_Token = as.matrix(DTM_Token)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 상위 키워드 추출</span></span><br><span class="line"><span class="comment"># quantile() 함수 활용</span></span><br><span class="line">top_1_pct = colSums(DTM_Matrix_Token) &gt; quantile(colSums(DTM_Matrix_Token), probs = <span class="number">0.99</span>)</span><br><span class="line"></span><br><span class="line">DTM_Matrix_Token_selected = DTM_Matrix_Token[, top_1_pct]</span><br><span class="line"></span><br><span class="line">ncol(DTM_Matrix_Token_selected)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Error</span></span><br><span class="line">DTM_df = as.data.frame(DTM_Matrix_Token_selected)</span><br><span class="line">DTM_df</span><br><span class="line"></span><br><span class="line">pos_final_df = cbind(pos_binary_df, DTM_df)</span><br><span class="line"></span><br><span class="line">glimpse(pos_final_df)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#희소행렬 문제가 나타나게 된다.</span></span><br><span class="line"></span><br><span class="line">ncol(pos_final_df)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="훈련-검증용-data-분류"><a href="#훈련-검증용-data-분류" class="headerlink" title="훈련, 검증용 data 분류"></a>훈련, 검증용 data 분류</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ---- 훈련 검증용 데이터 분류 ----</span></span><br><span class="line">set.seed(<span class="number">1234</span>)</span><br><span class="line">idx = sample(<span class="number">1</span>:nrow(pos_final_df), nrow(pos_final_df) * <span class="number">0.7</span>, replace = <span class="literal">FALSE</span>)</span><br><span class="line">train = pos_final_df[idx, ]</span><br><span class="line">test = pos_final_df[-idx, ]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="Logistic-Regression-Model-Develop"><a href="#Logistic-Regression-Model-Develop" class="headerlink" title="Logistic Regression Model Develop"></a>Logistic Regression Model Develop</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># --- 로지스틱 회귀 모형 개발 ---</span></span><br><span class="line"></span><br><span class="line">start_time = Sys.time()</span><br><span class="line"></span><br><span class="line">glm_model = step(glm(pos_binary ~ .,</span><br><span class="line">                     data = train[-<span class="number">1</span>],</span><br><span class="line">                     family = binomial(link = <span class="string">&quot;logit&quot;</span>)),</span><br><span class="line">                 direction = <span class="string">&quot;backward&quot;</span>) <span class="comment"># 후진소거법</span></span><br><span class="line"></span><br><span class="line">End_time = Sys.time()</span><br><span class="line">difftime(End_time, start_time, units = <span class="string">&quot;secs&quot;</span>)</span><br></pre></td></tr></table></figure>






<h4 id="Step-AIC-2202-56"><a href="#Step-AIC-2202-56" class="headerlink" title="Step:  AIC=2202.56"></a>Step:  AIC=2202.56</h4><ul>
<li>Logistic regression 안의 평가 기준</li>
<li>낮을 수록 좋다. </li>
</ul>
<blockquote>
<p>Step:  AIC=2202.2<br>pos_binary ~ love + veri + just + size + dress + fit + will +<br>    back + like + tri + flatter + top + length + realli + shirt +<br>    materi</p>
</blockquote>
<p><img src="/../../imeges/R_images/AIC_LogisticR.png" alt="AIC_LogisticR"></p>
<h3 id="모형-성능-측정"><a href="#모형-성능-측정" class="headerlink" title="모형 성능 측정"></a>모형 성능 측정</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ---- 모형 성능 측정 ----</span></span><br><span class="line"><span class="comment"># install.packages(&quot;pROC&quot;)</span></span><br><span class="line">library(pROC)</span><br><span class="line">preds = predict(glm_model, newdata = test, type = <span class="string">&quot;response&quot;</span>)</span><br><span class="line">roc_glm = roc(test$pos_binary, preds)</span><br><span class="line">plot.roc(roc_glm, print.auc=<span class="literal">TRUE</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/../../imeges/R_images/R_calssification_pROC.png" alt="R_calssification_pROC"></p>
<h3 id="정리"><a href="#정리" class="headerlink" title="정리"></a>정리</h3><pre><code>1. 정형 데이터 가져 오기 
2. 정형 데이터 가공
    - 좋아요 수를 활용하여 긍정/부정 data 나눔
3. 정형 데이터 분리 : 텍스트 데이터 따로 분리 
4. 텍스트 데이터 처리 (전처리, 토큰화, 코퍼스, DTM)
5. 텍스트 데이터 + 기존 data 합침
6. ML 모형 진행 (다른 모형을 진행 해도 된다. )
</code></pre>
<hr>
<p>하지만, 혹시 지금까지 배운 내용이 너무 어렵다면 python으로만 하는 것도<br>나쁘지 않다. </p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2021-12-15T08:11:16.000Z" title="2021. 12. 15. 오후 5:11:16">2021-12-15</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2021-12-15T09:46:54.510Z" title="2021. 12. 15. 오후 6:46:54">2021-12-15</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/machineLeaning/">machineLeaning</a></span><span class="level-item">19분안에 읽기 (약 2920 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/12/15/python/MachineLearning_Test_/">Text Mining in Python</a></h1><div class="content"><h2 id="개요"><a href="#개요" class="headerlink" title="개요"></a>개요</h2><ul>
<li>빅데이터 분석 및 시각화 &amp; 텍스트 마이닝<br><br><br></li>
</ul>
<ul>
<li>Ref01_ <a target="_blank" rel="noopener" href="https://wikidocs.net/92112">Matplotlib 히스토그램 그리기</a></li>
<li>Ref02_ <a target="_blank" rel="noopener" href="https://wikidocs.net/94600">딥 러닝을 이용한 자연어 처리 입문</a></li>
<li>네이버 쇼핑 리뷰 감성 분류하기(Naver Shopping Review Sentiment Analysis)</li>
</ul>
<p><br><br></p>
<hr>
<h2 id="평가"><a href="#평가" class="headerlink" title="평가"></a>평가</h2><ul>
<li>다음은 네이버 쇼핑 리뷰 감성 분류하기 예제입니다. </li>
<li>빈칸에 <code># 코드 입력</code>란에 적당한 코드를 작성하시기를 바랍니다. </li>
<li>각 빈칸당 10점입니다. </li>
</ul>
<h3 id="Colab에-Mecab-설치"><a href="#Colab에-Mecab-설치" class="headerlink" title="Colab에 Mecab 설치"></a>Colab에 Mecab 설치</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Colab에 Mecab 설치</span></span><br><span class="line">!git clone https://github.com/SOMJANG/Mecab-ko-<span class="keyword">for</span>-Google-Colab.git</span><br><span class="line">%cd Mecab-ko-<span class="keyword">for</span>-Google-Colab</span><br><span class="line">!bash install_mecab-ko_on_colab190912.sh</span><br></pre></td></tr></table></figure>

<pre><code>Cloning into &#39;Mecab-ko-for-Google-Colab&#39;...
remote: Enumerating objects: 91, done.[K
remote: Total 91 (delta 0), reused 0 (delta 0), pack-reused 91[K
Unpacking objects: 100% (91/91), done.
/content/Mecab-ko-for-Google-Colab
Installing konlpy.....
Collecting konlpy
  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)
[K     |████████████████████████████████| 19.4 MB 2.4 MB/s 
[?25hCollecting JPype1&gt;=0.7.0
  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)
[K     |████████████████████████████████| 448 kB 23.5 MB/s 
[?25hRequirement already satisfied: lxml&gt;=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)
Collecting colorama
  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)
Requirement already satisfied: tweepy&gt;=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)
Requirement already satisfied: numpy&gt;=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)
Collecting beautifulsoup4==4.6.0
  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)
[K     |████████████████████████████████| 86 kB 2.4 MB/s 
[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1&gt;=0.7.0-&gt;konlpy) (3.10.0.2)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy&gt;=3.7.0-&gt;konlpy) (1.3.0)
Requirement already satisfied: requests[socks]&gt;=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy&gt;=3.7.0-&gt;konlpy) (2.23.0)
Requirement already satisfied: six&gt;=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy&gt;=3.7.0-&gt;konlpy) (1.15.0)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;tweepy&gt;=3.7.0-&gt;konlpy) (3.1.1)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]&gt;=2.11.1-&gt;tweepy&gt;=3.7.0-&gt;konlpy) (1.24.3)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]&gt;=2.11.1-&gt;tweepy&gt;=3.7.0-&gt;konlpy) (3.0.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]&gt;=2.11.1-&gt;tweepy&gt;=3.7.0-&gt;konlpy) (2021.10.8)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]&gt;=2.11.1-&gt;tweepy&gt;=3.7.0-&gt;konlpy) (2.10)
Requirement already satisfied: PySocks!=1.5.7,&gt;=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]&gt;=2.11.1-&gt;tweepy&gt;=3.7.0-&gt;konlpy) (1.7.1)
Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy
  Attempting uninstall: beautifulsoup4
    Found existing installation: beautifulsoup4 4.6.3
    Uninstalling beautifulsoup4-4.6.3:
      Successfully uninstalled beautifulsoup4-4.6.3
Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2
Done
Installing mecab-0.996-ko-0.9.2.tar.gz.....
Downloading mecab-0.996-ko-0.9.2.tar.gz.......
from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz
--2021-12-15 08:19:45--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz
Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c0:3470, 2406:da00:ff00::22e9:9f55, ...
Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=Djk%2BX4VYfoZUGHzDRgTrcVVdFvE%3D&amp;Expires=1639557778&amp;AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&amp;versionId=null&amp;response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&amp;response-content-encoding=None [following]
--2021-12-15 08:19:46--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=Djk%2BX4VYfoZUGHzDRgTrcVVdFvE%3D&amp;Expires=1639557778&amp;AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&amp;versionId=null&amp;response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&amp;response-content-encoding=None
Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.113.163
Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.113.163|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1414979 (1.3M) [application/x-tar]
Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’

mecab-0.996-ko-0.9. 100%[===================&gt;]   1.35M  1.07MB/s    in 1.3s    

2021-12-15 08:19:48 (1.07 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]

Done
Unpacking mecab-0.996-ko-0.9.2.tar.gz.......
Done
Change Directory to mecab-0.996-ko-0.9.2.......
installing mecab-0.996-ko-0.9.2.tar.gz........
configure
make
make check
make install
ldconfig
Done
Change Directory to /content
Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......
from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz
--2021-12-15 08:21:19--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz
Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::6b17:d1f5, 2406:da00:ff00::22cd:e0db, ...
Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=ZNAR2x6%2FNWxJ4p%2BOkG%2BjdG77Dqk%3D&amp;Expires=1639558279&amp;AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&amp;versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&amp;response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&amp;response-content-encoding=None [following]
--2021-12-15 08:21:19--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=ZNAR2x6%2FNWxJ4p%2BOkG%2BjdG77Dqk%3D&amp;Expires=1639558279&amp;AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&amp;versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&amp;response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&amp;response-content-encoding=None
Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 54.231.82.195
Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|54.231.82.195|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 49775061 (47M) [application/x-tar]
Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’

mecab-ko-dic-2.1.1- 100%[===================&gt;]  47.47M  13.0MB/s    in 4.5s    

2021-12-15 08:21:25 (10.5 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]

Done
Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......
Done
Change Directory to mecab-ko-dic-2.1.1-20180720
Done
installing........
configure
make
make install
apt-get update
apt-get upgrade
apt install curl
apt install git
bash &lt;(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)
Done
Successfully Installed
Now you can use Mecab
from konlpy.tag import Mecab
mecab = Mecab()
사용자 사전 추가 방법 : https://bit.ly/3k0ZH53
NameError: name &#39;Tagger&#39; is not defined 오류 발생 시 런타임을 재실행 해주세요
블로그에 해결 방법을 남겨주신 tana님 감사합니다.
</code></pre>
<h2 id="네이버-쇼핑-리뷰-데이터에-대한-이해와-전처리"><a href="#네이버-쇼핑-리뷰-데이터에-대한-이해와-전처리" class="headerlink" title="네이버 쇼핑 리뷰 데이터에 대한 이해와 전처리"></a>네이버 쇼핑 리뷰 데이터에 대한 이해와 전처리</h2><ul>
<li></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">from</span> konlpy.tag <span class="keyword">import</span> Mecab</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br></pre></td></tr></table></figure>

<h2 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">urllib.request.urlretrieve(<span class="string">&quot;https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/naver_shopping.txt&quot;</span>, filename=<span class="string">&quot;ratings_total.txt&quot;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>(&#39;ratings_total.txt&#39;, &lt;http.client.HTTPMessage at 0x7f7d3557f750&gt;)
</code></pre>
<ul>
<li>해당 데이터에는 열 제목이 별도로 없음. 그래서 임의로 두 개의 열제목인 “ratings”와 “reviews” 추가</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># (1) 데이터 불러오고, 전체 리뷰 개수 출력 # 200,000</span></span><br><span class="line">totalDt = pd.read_table(<span class="string">&#x27;ratings_total.txt&#x27;</span>, names=[<span class="string">&#x27;ratings&#x27;</span>, <span class="string">&#x27;reviews&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;전체 리뷰 개수 :&#x27;</span>,<span class="built_in">len</span>(totalDt)) <span class="comment"># 전체 리뷰 개수 출력</span></span><br></pre></td></tr></table></figure>

<pre><code>전체 리뷰 개수 : 200000
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">totalDt[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ratings</th>
      <th>reviews</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5</td>
      <td>배공빠르고 굿</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>
    </tr>
  </tbody>
</table>
</div>



<ul>
<li>훈련 데이터와 테스트 데이터 분리하기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">totalDt[<span class="string">&#x27;label&#x27;</span>] = np.select([totalDt.ratings &gt; <span class="number">3</span>], [<span class="number">1</span>], default=<span class="number">0</span>)</span><br><span class="line">totalDt[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ratings</th>
      <th>reviews</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5</td>
      <td>배공빠르고 굿</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



<ul>
<li>각 열에 대해서 중복을 제외한 샘플의 수 카운트</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">totalDt[<span class="string">&#x27;ratings&#x27;</span>].nunique(), totalDt[<span class="string">&#x27;reviews&#x27;</span>].nunique(), totalDt[<span class="string">&#x27;label&#x27;</span>].nunique()</span><br></pre></td></tr></table></figure>




<pre><code>(4, 199908, 2)
</code></pre>
<ul>
<li>ratings열의 경우 1, 2, 4, 5라는 네 가지 값을 가지고 있습니다. reviews열에서 중복을 제외한 경우 199,908개입니다. 현재 20만개의 리뷰가 존재하므로 이는 현재 갖고 있는 데이터에 중복인 샘플들이 있다는 의미입니다. 중복인 샘플들을 제거해줍니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># (2) review열에서 중복 데이터 제거 drop_duplicates() 함수 활용</span></span><br><span class="line">totalDt.drop_duplicates(subset=[<span class="string">&#x27;reviews&#x27;</span>], inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;총 샘플의 수 :&#x27;</span>,<span class="built_in">len</span>(totalDt))</span><br></pre></td></tr></table></figure>

<pre><code>총 샘플의 수 : 199908
</code></pre>
<ul>
<li>NULL 값 유무 확인</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(totalDt.isnull().values.<span class="built_in">any</span>())</span><br></pre></td></tr></table></figure>

<pre><code>False
</code></pre>
<ul>
<li>훈련 데이터와 테스트 데이터를 3:1 비율로 분리</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_data, test_data = train_test_split(totalDt, test_size = <span class="number">0.25</span>, random_state = <span class="number">42</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;훈련용 리뷰의 개수 :&#x27;</span>, <span class="built_in">len</span>(train_data))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;테스트용 리뷰의 개수 :&#x27;</span>, <span class="built_in">len</span>(test_data))</span><br></pre></td></tr></table></figure>

<pre><code>훈련용 리뷰의 개수 : 149931
테스트용 리뷰의 개수 : 49977
</code></pre>
<h2 id="레이블의-분포-확인"><a href="#레이블의-분포-확인" class="headerlink" title="레이블의 분포 확인"></a>레이블의 분포 확인</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># (3) label 1, 0 막대그래프 그리기</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>,<span class="number">1</span>,figsize=(<span class="number">7</span>,<span class="number">5</span>))</span><br><span class="line">width = <span class="number">0.15</span></span><br><span class="line"></span><br><span class="line">plot_Dt= train_data[<span class="string">&#x27;label&#x27;</span>].value_counts().plot(kind = <span class="string">&#x27;bar&#x27;</span>, color=<span class="string">&#x27;orange&#x27;</span>, edgecolor=<span class="string">&#x27;black&#x27;</span>).legend()</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;train_data&#x27;</span>,fontsize=<span class="number">20</span>) <span class="comment">## 타이틀 출력</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;Count&#x27;</span>,fontsize=<span class="number">10</span>) <span class="comment">## y축 라벨 출력</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img src="/../../imeges/python/output_22_0.png" alt="train_data"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train_data.groupby(<span class="string">&#x27;label&#x27;</span>).size().reset_index(name = <span class="string">&#x27;count&#x27;</span>))</span><br></pre></td></tr></table></figure>

<pre><code>   label  count
0      0  74918
1      1  75013
</code></pre>
<ul>
<li>두 레이블 모두 약 7만 5천개로 50:50 비율을 가짐</li>
</ul>
<h2 id="데이터-정제하기"><a href="#데이터-정제하기" class="headerlink" title="데이터 정제하기"></a>데이터 정제하기</h2><ul>
<li>정규 표현식을 사용하여 한글을 제외하고 모두 제거해줍니다. </li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 한글과 공백을 제외하고 모두 제거</span></span><br><span class="line"><span class="comment"># (4) 한글 및 공백 제외한 모든 글자 제거</span></span><br><span class="line">train_data[<span class="string">&#x27;reviews&#x27;</span>] = train_data[<span class="string">&#x27;reviews&#x27;</span>].<span class="built_in">str</span>.replace(<span class="string">&quot;[^ㄱ-ㅎㅏ-ㅣ가-힣 ]&quot;</span>,<span class="string">&quot;&quot;</span>)</span><br><span class="line">train_data[<span class="string">&#x27;reviews&#x27;</span>].replace(<span class="string">&#x27;&#x27;</span>, np.nan, inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(train_data.isnull().<span class="built_in">sum</span>())</span><br></pre></td></tr></table></figure>

<pre><code>ratings    0
reviews    0
label      0
dtype: int64
</code></pre>
<ul>
<li>테스트 데이터에 대해서도 같은 과정을 거칩니다. </li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># (5) 데스트 데이터에 적용하기</span></span><br><span class="line"><span class="comment"># 코드 1 중복 제거</span></span><br><span class="line"><span class="comment"># 코드 2 정규 표현식 수행</span></span><br><span class="line"><span class="comment"># 코드 3 공백은 Null 값으로 변경</span></span><br><span class="line"><span class="comment"># 코드 4 Null 값 제거</span></span><br><span class="line">test_data.drop_duplicates(subset = [<span class="string">&#x27;reviews&#x27;</span>], inplace=<span class="literal">True</span>) <span class="comment"># 중복 제거</span></span><br><span class="line">test_data[<span class="string">&#x27;reviews&#x27;</span>] = test_data[<span class="string">&#x27;reviews&#x27;</span>].<span class="built_in">str</span>.replace(<span class="string">&quot;[^ㄱ-ㅎㅏ-ㅣ가-힣 ]&quot;</span>,<span class="string">&quot;&quot;</span>) <span class="comment"># 정규 표현식 수행</span></span><br><span class="line">test_data[<span class="string">&#x27;reviews&#x27;</span>].replace(<span class="string">&#x27;&#x27;</span>, np.nan, inplace=<span class="literal">True</span>) <span class="comment"># 공백은 Null 값으로 변경</span></span><br><span class="line">test_data = test_data.dropna(how=<span class="string">&#x27;any&#x27;</span>) <span class="comment"># Null 값 제거</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;전처리 후 테스트용 샘플의 개수 :&#x27;</span>,<span class="built_in">len</span>(test_data))</span><br></pre></td></tr></table></figure>

<pre><code>전처리 후 테스트용 샘플의 개수 : 49977
</code></pre>
<h2 id="토큰화"><a href="#토큰화" class="headerlink" title="토큰화"></a>토큰화</h2><ul>
<li>형태소 분석기 Mecab을 사용하여 토큰화 작업을 수행한다. </li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># (6) Mecab 클래스 호출하기</span></span><br><span class="line">mecab = Mecab()</span><br><span class="line"><span class="built_in">print</span>(mecab.morphs(<span class="string">&#x27;와 이런 것도 상품이라고 차라리 내가 만드는 게 나을 뻔&#x27;</span>))</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;와&#39;, &#39;이런&#39;, &#39;것&#39;, &#39;도&#39;, &#39;상품&#39;, &#39;이&#39;, &#39;라고&#39;, &#39;차라리&#39;, &#39;내&#39;, &#39;가&#39;, &#39;만드&#39;, &#39;는&#39;, &#39;게&#39;, &#39;나을&#39;, &#39;뻔&#39;]
</code></pre>
<ul>
<li>불용어를 지정하여 필요없는 토큰들을 제거하도록 한다. </li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># (7) 불용어 만들기</span></span><br><span class="line">stopwords = [<span class="string">&#x27;도&#x27;</span>, <span class="string">&#x27;는&#x27;</span>, <span class="string">&#x27;다&#x27;</span>, <span class="string">&#x27;의&#x27;</span>, <span class="string">&#x27;가&#x27;</span>, <span class="string">&#x27;이&#x27;</span>, <span class="string">&#x27;은&#x27;</span>, <span class="string">&#x27;한&#x27;</span>, <span class="string">&#x27;에&#x27;</span>, <span class="string">&#x27;하&#x27;</span>, <span class="string">&#x27;고&#x27;</span>, <span class="string">&#x27;을&#x27;</span>, <span class="string">&#x27;를&#x27;</span>, <span class="string">&#x27;인&#x27;</span>, <span class="string">&#x27;듯&#x27;</span>, <span class="string">&#x27;과&#x27;</span>, <span class="string">&#x27;와&#x27;</span>, <span class="string">&#x27;네&#x27;</span>, <span class="string">&#x27;들&#x27;</span>, <span class="string">&#x27;듯&#x27;</span>, <span class="string">&#x27;지&#x27;</span>, <span class="string">&#x27;임&#x27;</span>, <span class="string">&#x27;게&#x27;</span>]</span><br></pre></td></tr></table></figure>

<ul>
<li>훈련 데이터와 테스트 데이터에 대해서 동일한 과정을 거친다. </li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_data[<span class="string">&#x27;tokenized&#x27;</span>] = train_data[<span class="string">&#x27;reviews&#x27;</span>].apply(mecab.morphs)</span><br><span class="line">train_data[<span class="string">&#x27;tokenized&#x27;</span>] = train_data[<span class="string">&#x27;tokenized&#x27;</span>].apply(<span class="keyword">lambda</span> x: [item <span class="keyword">for</span> item <span class="keyword">in</span> x <span class="keyword">if</span> item <span class="keyword">not</span> <span class="keyword">in</span> stopwords])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_data[<span class="string">&#x27;tokenized&#x27;</span>] = test_data[<span class="string">&#x27;reviews&#x27;</span>].apply(mecab.morphs)</span><br><span class="line">test_data[<span class="string">&#x27;tokenized&#x27;</span>] = test_data[<span class="string">&#x27;tokenized&#x27;</span>].apply(<span class="keyword">lambda</span> x: [item <span class="keyword">for</span> item <span class="keyword">in</span> x <span class="keyword">if</span> item <span class="keyword">not</span> <span class="keyword">in</span> stopwords])</span><br></pre></td></tr></table></figure>

<h2 id="단어와-길이-분포-확인하기"><a href="#단어와-길이-분포-확인하기" class="headerlink" title="단어와 길이 분포 확인하기"></a>단어와 길이 분포 확인하기</h2><p>긍정 리뷰에는 주로 어떤 단어들이 많이 등장하고, 부정 리뷰에는 주로 어떤 단어들이 등장하는지 두 가지 경우에 대해서 각 단어의 빈도수를 계산해보겠습니다. 각 레이블에 따라서 별도로 단어들의 리스트를 저장해줍니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">negative_W = np.hstack(train_data[train_data.label == <span class="number">0</span>][<span class="string">&#x27;tokenized&#x27;</span>].values)</span><br><span class="line">positive_W = np.hstack(train_data[train_data.label == <span class="number">1</span>][<span class="string">&#x27;tokenized&#x27;</span>].values)</span><br><span class="line">negative_W</span><br><span class="line">positive_W</span><br></pre></td></tr></table></figure>




<pre><code>array([&#39;적당&#39;, &#39;만족&#39;, &#39;합니다&#39;, ..., &#39;잘&#39;, &#39;삿&#39;, &#39;어요&#39;], dtype=&#39;&lt;U25&#39;)
</code></pre>
<ul>
<li>Counter()를 사용하여 각 단어에 대한 빈도수를 카운트한다. 우선 부정 리뷰에 대해서 빈도수가 높은 상위 20개 단어 출력</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">negative_word_count = Counter(negative_W)</span><br><span class="line"><span class="built_in">print</span>(negative_word_count.most_common(<span class="number">20</span>))</span><br></pre></td></tr></table></figure>

<pre><code>[(&#39;네요&#39;, 31799), (&#39;는데&#39;, 20295), (&#39;안&#39;, 19718), (&#39;어요&#39;, 14849), (&#39;있&#39;, 13200), (&#39;너무&#39;, 13058), (&#39;했&#39;, 11783), (&#39;좋&#39;, 9812), (&#39;배송&#39;, 9677), (&#39;같&#39;, 8997), (&#39;구매&#39;, 8876), (&#39;어&#39;, 8869), (&#39;거&#39;, 8854), (&#39;없&#39;, 8670), (&#39;아요&#39;, 8642), (&#39;습니다&#39;, 8436), (&#39;그냥&#39;, 8355), (&#39;되&#39;, 8345), (&#39;잘&#39;, 8029), (&#39;않&#39;, 7984)]
</code></pre>
<p>‘네요’, ‘는데’, ‘안’, ‘않’, ‘너무’, ‘없’ 등과 같은 단어들이 부정 리뷰에서 주로 등장합니다. 긍정 리뷰에 대해서도 동일하게 출력해봅시다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">positive_word_count = Counter(positive_W)</span><br><span class="line"><span class="built_in">print</span>(positive_word_count.most_common(<span class="number">20</span>))</span><br></pre></td></tr></table></figure>

<pre><code>[(&#39;좋&#39;, 39488), (&#39;아요&#39;, 21184), (&#39;네요&#39;, 19895), (&#39;어요&#39;, 18686), (&#39;잘&#39;, 18602), (&#39;구매&#39;, 16171), (&#39;습니다&#39;, 13320), (&#39;있&#39;, 12391), (&#39;배송&#39;, 12275), (&#39;는데&#39;, 11670), (&#39;했&#39;, 9818), (&#39;합니다&#39;, 9801), (&#39;먹&#39;, 9635), (&#39;재&#39;, 9273), (&#39;너무&#39;, 8397), (&#39;같&#39;, 7868), (&#39;만족&#39;, 7261), (&#39;거&#39;, 6482), (&#39;어&#39;, 6294), (&#39;쓰&#39;, 6292)]
</code></pre>
<p>‘좋’, ‘아요’, ‘네요’, ‘잘’, ‘너무’, ‘만족’ 등과 같은 단어들이 주로 많이 등장합니다. 두 가지 경우에 대해서 각각 길이 분포를 확인해봅시다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># (8) 긍정 리뷰와 부정 리뷰 히스토그램 작성하기</span></span><br><span class="line"></span><br><span class="line">fig,(ax1,ax2) = plt.subplots(<span class="number">1</span>,<span class="number">2</span>,figsize=(<span class="number">9</span>,<span class="number">5</span>))</span><br><span class="line">text_len = train_data[train_data[<span class="string">&#x27;label&#x27;</span>]==<span class="number">1</span>][<span class="string">&#x27;tokenized&#x27;</span>].<span class="built_in">map</span>(<span class="keyword">lambda</span> x: <span class="built_in">len</span>(x))</span><br><span class="line">ax1.hist(text_len, color=<span class="string">&#x27;pink&#x27;</span>, edgecolor=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">ax1.set_title(<span class="string">&#x27;Positive Reviews&#x27;</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">&#x27;length of samples&#x27;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&#x27;number of samples&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;긍정 리뷰의 평균 길이 :&#x27;</span>, np.mean(text_len))</span><br><span class="line"></span><br><span class="line">text_len = train_data[train_data[<span class="string">&#x27;label&#x27;</span>]==<span class="number">0</span>][<span class="string">&#x27;tokenized&#x27;</span>].<span class="built_in">map</span>(<span class="keyword">lambda</span> x: <span class="built_in">len</span>(x))</span><br><span class="line">ax2.hist(text_len, color=<span class="string">&#x27;skyblue&#x27;</span>, edgecolor=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">ax2.set_title(<span class="string">&#x27;부정 리뷰&#x27;</span>)</span><br><span class="line">ax2.set_title(<span class="string">&#x27;Negative Reviews&#x27;</span>)</span><br><span class="line">fig.suptitle(<span class="string">&#x27;Words in texts&#x27;</span>)</span><br><span class="line">ax2.set_xlabel(<span class="string">&#x27;length of samples&#x27;</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">&#x27;number of samples&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;부정 리뷰의 평균 길이 :&#x27;</span>, np.mean(text_len))</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>긍정 리뷰의 평균 길이 : 13.5877381253916
부정 리뷰의 평균 길이 : 17.02948557089084
</code></pre>
<p><img src="/../../imeges/python/output_43_1.png" alt="Review_Histogram"></p>
<ul>
<li>긍정 리뷰보다는 부정 리뷰가 좀 더 길게 작성된 경향이 있는 것 같다. </li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X_train = train_data[<span class="string">&#x27;tokenized&#x27;</span>].values</span><br><span class="line">y_train = train_data[<span class="string">&#x27;label&#x27;</span>].values</span><br><span class="line">X_test= test_data[<span class="string">&#x27;tokenized&#x27;</span>].values</span><br><span class="line">y_test = test_data[<span class="string">&#x27;label&#x27;</span>].values</span><br></pre></td></tr></table></figure>

<h2 id="정수-인코딩"><a href="#정수-인코딩" class="headerlink" title="정수 인코딩"></a>정수 인코딩</h2><ul>
<li>이제 기계가 텍스트를 숫자로 처리할 수 있도록 훈련 데이터와 테스트 데이터에 정수 인코딩을 수행해야 합니다. 우선, 훈련 데이터에 대해서 단어 집합(vocaburary)을 만들어봅시다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># (9) 정수 인코딩 클래스 호출 및 X_train 데이터에 적합하기</span></span><br><span class="line">tokenizer = Tokenizer()</span><br><span class="line">tokenizer.fit_on_texts(X_train)</span><br></pre></td></tr></table></figure>

<p>단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여되었습니다. 이는 tokenizer.word_index를 출력하여 확인 가능합니다. 등장 횟수가 1회인 단어들은 자연어 처리에서 배제하고자 합니다. 이 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인해봅시다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">threshold = <span class="number">2</span></span><br><span class="line">total_cnt = <span class="built_in">len</span>(tokenizer.word_index) <span class="comment"># 단어의 수</span></span><br><span class="line">rare_cnt = <span class="number">0</span> <span class="comment"># 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트</span></span><br><span class="line">total_freq = <span class="number">0</span> <span class="comment"># 훈련 데이터의 전체 단어 빈도수 총 합</span></span><br><span class="line">rare_freq = <span class="number">0</span> <span class="comment"># 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.</span></span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> tokenizer.word_counts.items():</span><br><span class="line">    total_freq = total_freq + value</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 단어의 등장 빈도수가 threshold보다 작으면</span></span><br><span class="line">    <span class="keyword">if</span>(value &lt; threshold):</span><br><span class="line">        rare_cnt = rare_cnt + <span class="number">1</span></span><br><span class="line">        rare_freq = rare_freq + value</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;단어 집합(vocabulary)의 크기 :&#x27;</span>,total_cnt)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;등장 빈도가 %s번 이하인 희귀 단어의 수: %s&#x27;</span>%(threshold - <span class="number">1</span>, rare_cnt))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;단어 집합에서 희귀 단어의 비율:&quot;</span>, (rare_cnt / total_cnt)*<span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;전체 등장 빈도에서 희귀 단어 등장 빈도 비율:&quot;</span>, (rare_freq / total_freq)*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>

<pre><code>단어 집합(vocabulary)의 크기 : 39998
등장 빈도가 1번 이하인 희귀 단어의 수: 18213
단어 집합에서 희귀 단어의 비율: 45.53477673883694
전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 0.7935698749320282
</code></pre>
<p>단어가 약 40,000개가 존재합니다. 등장 빈도가 threshold 값인 2회 미만. 즉, 1회인 단어들은 단어 집합에서 약 45%를 차지합니다. 하지만, 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 매우 적은 수치인 약 0.8%밖에 되지 않습니다. 아무래도 등장 빈도가 1회인 단어들은 자연어 처리에서 별로 중요하지 않을 듯 합니다. 그래서 이 단어들은 정수 인코딩 과정에서 배제시키겠습니다.</p>
<p>등장 빈도수가 1인 단어들의 수를 제외한 단어의 개수를 단어 집합의 최대 크기로 제한하겠습니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 전체 단어 개수 중 빈도수 2이하인 단어 개수는 제거.</span></span><br><span class="line"><span class="comment"># 0번 패딩 토큰과 1번 OOV 토큰을 고려하여 +2</span></span><br><span class="line">vocab_size = total_cnt - rare_cnt + <span class="number">2</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;단어 집합의 크기 :&#x27;</span>,vocab_size)</span><br></pre></td></tr></table></figure>

<pre><code>단어 집합의 크기 : 21787
</code></pre>
<p>이제 단어 집합의 크기는 21,787개입니다. 이를 토크나이저의 인자로 넘겨주면, 토크나이저는 텍스트 시퀀스를 숫자 시퀀스로 변환합니다. 이러한 정수 인코딩 과정에서 이보다 큰 숫자가 부여된 단어들은 OOV로 변환하겠습니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># (10) 토크나이저 클래스 호출 및 OOV 변환 코드 작성</span></span><br><span class="line"><span class="comment"># 코드 1</span></span><br><span class="line"><span class="comment"># 코드 2</span></span><br><span class="line"></span><br><span class="line">tokenizer = Tokenizer(vocab_size, oov_token = <span class="string">&#x27;OOV&#x27;</span>) </span><br><span class="line">tokenizer.fit_on_texts(X_train)</span><br><span class="line"></span><br><span class="line">X_train = tokenizer.texts_to_sequences(X_train)</span><br><span class="line">X_test = tokenizer.texts_to_sequences(X_test)</span><br></pre></td></tr></table></figure>

<p>정수 인코딩이 진행되었는지 확인하고자 X_train과 X_test에 대해서 상위 3개의 샘플만 출력합니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(X_train[:<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[[67, 2060, 299, 14259, 263, 73, 6, 236, 168, 137, 805, 2951, 625, 2, 77, 62, 207, 40, 1343, 155, 3, 6], [482, 409, 52, 8530, 2561, 2517, 339, 2918, 250, 2357, 38, 473, 2], [46, 24, 825, 105, 35, 2372, 160, 7, 10, 8061, 4, 1319, 29, 140, 322, 41, 59, 160, 140, 7, 1916, 2, 113, 162, 1379, 323, 119, 136]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(X_test[:<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[[14, 704, 767, 116, 186, 252, 12], [339, 3904, 62, 3816, 1651], [11, 69, 2, 49, 164, 3, 27, 15, 6, 1, 513, 289, 17, 92, 110, 564, 59, 7, 2]]
</code></pre>
<h2 id="패딩"><a href="#패딩" class="headerlink" title="패딩"></a>패딩</h2><p>이제 서로 다른 길이의 샘플들의 길이를 동일하게 맞춰주는 패딩 작업을 진행해보겠습니다. 전체 데이터에서 가장 길이가 긴 리뷰와 전체 데이터의 길이 분포를 알아보겠습니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;리뷰의 최대 길이 :&#x27;</span>,<span class="built_in">max</span>(<span class="built_in">len</span>(l) <span class="keyword">for</span> l <span class="keyword">in</span> X_train))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;리뷰의 평균 길이 :&#x27;</span>,<span class="built_in">sum</span>(<span class="built_in">map</span>(<span class="built_in">len</span>, X_train))/<span class="built_in">len</span>(X_train))</span><br><span class="line">plt.hist([<span class="built_in">len</span>(s) <span class="keyword">for</span> s <span class="keyword">in</span> X_train], bins=<span class="number">35</span>, label=<span class="string">&#x27;bins=35&#x27;</span>, color=<span class="string">&quot;skyblue&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length of samples&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;number of samples&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>리뷰의 최대 길이 : 85
리뷰의 평균 길이 : 15.307521459871541
</code></pre>
<p><img src="/../../imeges/python/output_58_1.png" alt="LengthOfReview"></p>
<p>리뷰의 최대 길이는 85, 평균 길이는 약 15입니다.</p>
<p>그리고 그래프로 봤을 때, 전체적으로는 60이하의 길이를 가지는 것으로 보입니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">below_threshold_len</span>(<span class="params">max_len, nested_list</span>):</span></span><br><span class="line">  count = <span class="number">0</span></span><br><span class="line">  <span class="keyword">for</span> sentence <span class="keyword">in</span> nested_list:</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">len</span>(sentence) &lt;= max_len):</span><br><span class="line">        count = count + <span class="number">1</span></span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&#x27;전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s&#x27;</span>%(max_len, (count / <span class="built_in">len</span>(nested_list))*<span class="number">100</span>))</span><br><span class="line"></span><br><span class="line">  </span><br></pre></td></tr></table></figure>

<ul>
<li>최대 길이가 85이므로 만약 80으로 패딩할 경우, 몇 개의 샘플들을 온전히 보전할 수 있는지 확인해봅시다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">max_len = <span class="number">80</span></span><br><span class="line">below_threshold_len(max_len, X_train)</span><br></pre></td></tr></table></figure>

<pre><code>전체 샘플 중 길이가 80 이하인 샘플의 비율: 99.99933302652553
</code></pre>
<p>훈련용 리뷰의 99.99%가 80이하의 길이를 가집니다. 훈련용 리뷰를 길이 80으로 패딩하겠습니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train = pad_sequences(X_train, maxlen = max_len)</span><br><span class="line">X_test = pad_sequences(X_test, maxlen = max_len)</span><br></pre></td></tr></table></figure>

<h1 id="GRU로-네이버-쇼핑-리뷰-감성-분류하기"><a href="#GRU로-네이버-쇼핑-리뷰-감성-분류하기" class="headerlink" title="GRU로 네이버 쇼핑 리뷰 감성 분류하기"></a>GRU로 네이버 쇼핑 리뷰 감성 분류하기</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Embedding, Dense, GRU</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> load_model</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.callbacks <span class="keyword">import</span> EarlyStopping, ModelCheckpoint</span><br><span class="line"></span><br><span class="line">embedding_dim = <span class="number">100</span></span><br><span class="line">hidden_units = <span class="number">128</span></span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(vocab_size, embedding_dim))</span><br><span class="line">model.add(GRU(hidden_units))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"></span><br><span class="line">es = EarlyStopping(monitor=<span class="string">&#x27;val_loss&#x27;</span>, mode=<span class="string">&#x27;min&#x27;</span>, verbose=<span class="number">1</span>, patience=<span class="number">4</span>)</span><br><span class="line">mc = ModelCheckpoint(<span class="string">&#x27;best_model.h5&#x27;</span>, monitor=<span class="string">&#x27;val_acc&#x27;</span>, mode=<span class="string">&#x27;max&#x27;</span>, verbose=<span class="number">1</span>, save_best_only=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;rmsprop&#x27;</span>, loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line">history = model.fit(X_train, y_train, epochs=<span class="number">15</span>, callbacks=[es, mc], batch_size=<span class="number">64</span>, validation_split=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sentiment_predict</span>(<span class="params">new_sentence</span>):</span></span><br><span class="line">  new_sentence = re.sub(<span class="string">r&#x27;[^ㄱ-ㅎㅏ-ㅣ가-힣 ]&#x27;</span>,<span class="string">&#x27;&#x27;</span>, new_sentence)</span><br><span class="line">  new_sentence = mecab.morphs(new_sentence) <span class="comment"># 토큰화</span></span><br><span class="line">  new_sentence = [word <span class="keyword">for</span> word <span class="keyword">in</span> new_sentence <span class="keyword">if</span> <span class="keyword">not</span> word <span class="keyword">in</span> stopwords] <span class="comment"># 불용어 제거</span></span><br><span class="line">  encoded = tokenizer.texts_to_sequences([new_sentence]) <span class="comment"># 정수 인코딩</span></span><br><span class="line">  pad_new = pad_sequences(encoded, maxlen = max_len) <span class="comment"># 패딩</span></span><br><span class="line"></span><br><span class="line">  score = <span class="built_in">float</span>(model.predict(pad_new)) <span class="comment"># 예측</span></span><br><span class="line">  <span class="keyword">if</span>(score &gt; <span class="number">0.5</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;:.2f&#125;% 확률로 긍정 리뷰입니다.&quot;</span>.<span class="built_in">format</span>(score * <span class="number">100</span>))</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;:.2f&#125;% 확률로 부정 리뷰입니다.&quot;</span>.<span class="built_in">format</span>((<span class="number">1</span> - score) * <span class="number">100</span>))</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/15
1875/1875 [==============================] - ETA: 0s - loss: 0.2725 - acc: 0.8967
Epoch 00001: val_acc improved from -inf to 0.91916, saving model to best_model.h5
1875/1875 [==============================] - 54s 25ms/step - loss: 0.2725 - acc: 0.8967 - val_loss: 0.2301 - val_acc: 0.9192
Epoch 2/15
1875/1875 [==============================] - ETA: 0s - loss: 0.2158 - acc: 0.9213
Epoch 00002: val_acc improved from 0.91916 to 0.92240, saving model to best_model.h5
1875/1875 [==============================] - 43s 23ms/step - loss: 0.2158 - acc: 0.9213 - val_loss: 0.2137 - val_acc: 0.9224
Epoch 3/15
1875/1875 [==============================] - ETA: 0s - loss: 0.1985 - acc: 0.9289
Epoch 00003: val_acc improved from 0.92240 to 0.92637, saving model to best_model.h5
1875/1875 [==============================] - 44s 24ms/step - loss: 0.1985 - acc: 0.9289 - val_loss: 0.2060 - val_acc: 0.9264
Epoch 4/15
1873/1875 [============================&gt;.] - ETA: 0s - loss: 0.1878 - acc: 0.9332
Epoch 00004: val_acc did not improve from 0.92637
1875/1875 [==============================] - 43s 23ms/step - loss: 0.1878 - acc: 0.9332 - val_loss: 0.2031 - val_acc: 0.9260
Epoch 5/15
1874/1875 [============================&gt;.] - ETA: 0s - loss: 0.1783 - acc: 0.9369
Epoch 00005: val_acc improved from 0.92637 to 0.92670, saving model to best_model.h5
1875/1875 [==============================] - 46s 24ms/step - loss: 0.1783 - acc: 0.9369 - val_loss: 0.2030 - val_acc: 0.9267
Epoch 6/15
1873/1875 [============================&gt;.] - ETA: 0s - loss: 0.1698 - acc: 0.9405
Epoch 00006: val_acc improved from 0.92670 to 0.92764, saving model to best_model.h5
1875/1875 [==============================] - 44s 24ms/step - loss: 0.1697 - acc: 0.9405 - val_loss: 0.2055 - val_acc: 0.9276
Epoch 7/15
1873/1875 [============================&gt;.] - ETA: 0s - loss: 0.1611 - acc: 0.9436
Epoch 00007: val_acc did not improve from 0.92764
1875/1875 [==============================] - 44s 24ms/step - loss: 0.1610 - acc: 0.9437 - val_loss: 0.2098 - val_acc: 0.9244
Epoch 8/15
1875/1875 [==============================] - ETA: 0s - loss: 0.1526 - acc: 0.9473
Epoch 00008: val_acc did not improve from 0.92764
1875/1875 [==============================] - 44s 23ms/step - loss: 0.1526 - acc: 0.9473 - val_loss: 0.2269 - val_acc: 0.9189
Epoch 9/15
1875/1875 [==============================] - ETA: 0s - loss: 0.1435 - acc: 0.9507
Epoch 00009: val_acc did not improve from 0.92764
1875/1875 [==============================] - 44s 24ms/step - loss: 0.1435 - acc: 0.9507 - val_loss: 0.2258 - val_acc: 0.9204
Epoch 00009: early stopping
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sentiment_predict(<span class="string">&#x27;이 상품 진짜 싫어요... 교환해주세요&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>99.03% 확률로 부정 리뷰입니다.
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sentiment_predict(<span class="string">&#x27;이 상품 진짜 좋아여... 강추합니다. &#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>99.51% 확률로 긍정 리뷰입니다.
</code></pre>
</div></article></div></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/../imeges/main.jpg" alt="YoonHwa Park"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">YoonHwa Park</p><p class="is-size-6 is-block">I am Living in the Mars</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Mars</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">포스트</p><a href="/archives"><p class="title">85</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">카테고리</p><a href="/categories"><p class="title">20</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">태그</p><a href="/tags"><p class="title">85</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://yoonhwa-p.github.io/" target="_blank" rel="noopener">팔로우</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/YoonHwa-P"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Instagram" href="https://www.instagram.com/1_haza"><i class="fab fa-instagram"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">링크</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">카테고리</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/BDS/"><span class="level-start"><span class="level-item">BDS</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/DecisionTree/"><span class="level-start"><span class="level-item">DecisionTree</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Markdown/"><span class="level-start"><span class="level-item">Markdown</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Python/Matplotlib/"><span class="level-start"><span class="level-item">Matplotlib</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Python/Matplotlib/Seaborn/"><span class="level-start"><span class="level-item">Seaborn</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/R/"><span class="level-start"><span class="level-item">R</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/R/data-science/"><span class="level-start"><span class="level-item">data_science</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/index/"><span class="level-start"><span class="level-item">index</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/init/"><span class="level-start"><span class="level-item">init</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/kaggle/"><span class="level-start"><span class="level-item">kaggle</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/naver/"><span class="level-start"><span class="level-item">naver</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/pharmacerical-company/"><span class="level-start"><span class="level-item">pharmacerical_company</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">23</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/Crawling/"><span class="level-start"><span class="level-item">Crawling</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machineLeaning/"><span class="level-start"><span class="level-item">machineLeaning</span></span><span class="level-end"><span class="level-item tag">13</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/machineLeaning/pycaret/"><span class="level-start"><span class="level-item">pycaret</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/machineLeaning/sklearn/"><span class="level-start"><span class="level-item">sklearn</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/python/theory/"><span class="level-start"><span class="level-item">theory</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/python-plotly/"><span class="level-start"><span class="level-item">python - plotly</span></span><span class="level-end"><span class="level-item tag">23</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">최근 글</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-01-03T08:48:48.000Z">2022-01-03</time></p><p class="title"><a href="/2022/01/03/python/Crowling_basic01/">Crawling_basic(01)</a></p><p class="categories"><a href="/categories/python/">python</a> / <a href="/categories/python/Crawling/">Crawling</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-12-24T23:40:13.000Z">2021-12-25</time></p><p class="title"><a href="/2021/12/25/python/ML_GridWearch_HP/">DTS: ML_Grid search(Hyper Parameter)</a></p><p class="categories"><a href="/categories/python/">python</a> / <a href="/categories/python/machineLeaning/">machineLeaning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-12-24T08:04:52.000Z">2021-12-24</time></p><p class="title"><a href="/2021/12/24/python/ML_ValidationCurveG(01)/">DTS: ML_Validation CurveG(01)</a></p><p class="categories"><a href="/categories/python/">python</a> / <a href="/categories/python/machineLeaning/">machineLeaning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-12-24T01:44:36.000Z">2021-12-24</time></p><p class="title"><a href="/2021/12/24/python/ML_LearningCurveG(01)/">DTS: ML_Learning CurveG(01)</a></p><p class="categories"><a href="/categories/python/">python</a> / <a href="/categories/python/machineLeaning/">machineLeaning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-12-22T03:15:10.000Z">2021-12-22</time></p><p class="title"><a href="/2021/12/22/python/DTS_PipeLine/">DTS: PipeLine 만들고 활용하기</a></p><p class="categories"><a href="/categories/python/">python</a> / <a href="/categories/python/machineLeaning/">machineLeaning</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">아카이브</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/01/"><span class="level-start"><span class="level-item">1월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/12/"><span class="level-start"><span class="level-item">12월 2021</span></span><span class="level-end"><span class="level-item tag">30</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/11/"><span class="level-start"><span class="level-item">11월 2021</span></span><span class="level-end"><span class="level-item tag">49</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/10/"><span class="level-start"><span class="level-item">10월 2021</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">태그</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/BarGraph/"><span class="tag">BarGraph</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bargraph/"><span class="tag">Bargraph</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BioDataScientist/"><span class="tag">BioDataScientist</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BioData-Science/"><span class="tag">BioData_Science</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Classifier/"><span class="tag">Classifier</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Crawling/"><span class="tag">Crawling</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DTS/"><span class="tag">DTS</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DataFrame/"><span class="tag">DataFrame</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DataScience/"><span class="tag">DataScience</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Decision-Tree/"><span class="tag">Decision Tree</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Donut-Chart/"><span class="tag">Donut_Chart</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/EDA/"><span class="tag">EDA</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HorizontalBar/"><span class="tag">HorizontalBar</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HyperParameter/"><span class="tag">HyperParameter</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/List/"><span class="tag">List</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Matplotlib/"><span class="tag">Matplotlib</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mow/"><span class="tag">Mow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Numpy/"><span class="tag">Numpy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pandas/"><span class="tag">Pandas</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Plotly/"><span class="tag">Plotly</span><span class="tag">22</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/R4ds/"><span class="tag">R4ds</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Rss/"><span class="tag">Rss</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scatter/"><span class="tag">Scatter</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ScatterLine/"><span class="tag">ScatterLine</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Seaborn/"><span class="tag">Seaborn</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Series/"><span class="tag">Series</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Stacked-Bar/"><span class="tag">Stacked_Bar</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Study/"><span class="tag">Study</span><span class="tag">19</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Subplots/"><span class="tag">Subplots</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Test-page/"><span class="tag">Test page,</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TextMining/"><span class="tag">TextMining</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Token/"><span class="tag">Token</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Treemap/"><span class="tag">Treemap</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tuple/"><span class="tag">Tuple</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/auto-Machine-Learning/"><span class="tag">auto Machine Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/bioinformatics/"><span class="tag">bioinformatics</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/coding/"><span class="tag">coding</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/dataScience/"><span class="tag">dataScience</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/decisionTree/"><span class="tag">decisionTree</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/draft/"><span class="tag">draft</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ggplot2/"><span class="tag">ggplot2</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/github/"><span class="tag">github</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/google-colaboratory-github-upload/"><span class="tag">google, colaboratory, github, upload</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/googleColab/"><span class="tag">googleColab</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/green/"><span class="tag">green</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/howtoGithub/"><span class="tag">howtoGithub</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/kaggle/"><span class="tag">kaggle</span><span class="tag">32</span></a></div><div class="control"><a class="tags has-addons" href="/tags/kaggleNote/"><span class="tag">kaggleNote</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/kaggle-Competition/"><span class="tag">kaggle_Competition</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/kaggle-dictation/"><span class="tag">kaggle_dictation</span><span class="tag">20</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machineLeaning/"><span class="tag">machineLeaning</span><span class="tag">13</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machineLearning/"><span class="tag">machineLearning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/make/"><span class="tag">make</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/makeBlog/"><span class="tag">makeBlog</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/makeBlog-makegithub/"><span class="tag">makeBlog, makegithub</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/makegithub/"><span class="tag">makegithub</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/markdown/"><span class="tag">markdown</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/market/"><span class="tag">market</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/method/"><span class="tag">method</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/model-selection/"><span class="tag">model selection</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/multiplace/"><span class="tag">multiplace</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/namespace/"><span class="tag">namespace</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/naver/"><span class="tag">naver</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/panel/"><span class="tag">panel</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/paperReview/"><span class="tag">paperReview</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pipe/"><span class="tag">pipe</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/plot/"><span class="tag">plot</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/prediction/"><span class="tag">prediction</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/predictionModel/"><span class="tag">predictionModel</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pycaret/"><span class="tag">pycaret</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">28</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pythonFuction/"><span class="tag">pythonFuction</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python-basic/"><span class="tag">python_basic</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/regression/"><span class="tag">regression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/repository/"><span class="tag">repository</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sklearn/"><span class="tag">sklearn</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/soil/"><span class="tag">soil</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/studyPython/"><span class="tag">studyPython</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/summary/"><span class="tag">summary</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/table/"><span class="tag">table</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/table-arrange/"><span class="tag">table arrange</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/timer/"><span class="tag">timer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/title/"><span class="tag">title</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EA%B9%83%ED%97%88%EB%B8%8C/"><span class="tag">깃허브</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">업데이트 소식 받기</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="구독"></div></div></form></div></div></div><div class="card widget" data-type="adsense"><div class="card-content"><div class="menu"><h3 class="menu-label">광고</h3><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9661048314566450" data-ad-slot="anonymous" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="구독"></div></div></form></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/../imeges/main.jpg" alt="Life in the Mars" height="28"></a><p class="is-size-7"><span>&copy; 2022 YoonHwa</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9661048314566450"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("ko");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="맨 위로" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-right",
        content: {
          message: "이 웹 사이트는 귀하의 경험을 향상시키기 위해 Cookie를 사용합니다.",
          dismiss: "무시",
          allow: "허용",
          deny: "거부",
          link: "더 알아보기",
          policy: "Cookie 정책",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="입력 하세요..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"입력 하세요...","untitled":"(제목 없음)","posts":"포스트","pages":"페이지","categories":"카테고리","tags":"태그"});
        });</script></body></html>